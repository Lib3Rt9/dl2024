{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a2be59-1599-488c-a07e-be32e73da290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # to process the data\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3e9f9f-ff9b-40a2-bf06-8894b36a5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 20\n",
      "Dimensions of each image: (150, 150, 3)\n",
      "Total dimensions of the dataset (assuming all images have the same shape): 20 x (150, 150, 3)\n",
      "Train set size: 15, Validation set size: 3, Test set size: 2\n",
      "Unique classes in the training set: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Number of classes for prediction: 10\n"
     ]
    }
   ],
   "source": [
    "class FlowerDataset:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "    def load_data(self):\n",
    "        image_files = os.listdir(self.directory)\n",
    "        for img in image_files[:20]:\n",
    "            try:\n",
    "                img_path = os.path.join(self.directory, img)\n",
    "                with Image.open(img_path) as img_array:\n",
    "                    resized_array = img_array.resize((150, 150))\n",
    "                    self.images.append(np.array(resized_array))\n",
    "                    label = img.split('_')[0]\n",
    "                    self.labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        max_pixel_value = 255.0\n",
    "        self.images = [image / max_pixel_value for image in self.images]\n",
    "\n",
    "    def print_dataset_dimensions(self):\n",
    "        if self.images:\n",
    "            print(f\"Total number of images: {len(self.images)}\")\n",
    "            print(f\"Dimensions of each image: {self.images[0].shape}\")\n",
    "            print(f\"Total dimensions of the dataset (assuming all images have the same shape): {len(self.images)} x {self.images[0].shape}\")\n",
    "        else:\n",
    "            print(\"The dataset is empty or not loaded properly.\")\n",
    "\n",
    "    def one_hot_encode(self):\n",
    "        unique_labels = sorted(set(self.labels))\n",
    "        label_to_int = {label: index for index, label in enumerate(unique_labels)}\n",
    "        self.label_indices = [label_to_int[label] for label in self.labels]\n",
    "        self.labels = [[int(i == label_index) for i in range(len(unique_labels))] for label_index in self.label_indices]\n",
    "\n",
    "def split_data(images, labels, train_ratio, validation_ratio, test_ratio):\n",
    "    combined = list(zip(images, labels))\n",
    "    shuffle(combined)\n",
    "    shuffled_images, shuffled_labels = zip(*combined)\n",
    "\n",
    "    train_end = int(len(shuffled_images) * train_ratio)\n",
    "    validation_end = train_end + int(len(shuffled_images) * validation_ratio)\n",
    "\n",
    "    x_train = shuffled_images[:train_end]\n",
    "    y_train = shuffled_labels[:train_end]\n",
    "    x_val = shuffled_images[train_end:validation_end]\n",
    "    y_val = shuffled_labels[train_end:validation_end]\n",
    "    x_test = shuffled_images[validation_end:]\n",
    "    y_test = shuffled_labels[validation_end:]\n",
    "\n",
    "    return list(x_train), list(x_val), list(x_test), list(y_train), list(y_val), list(y_test)\n",
    "\n",
    "# Usage\n",
    "dataset = FlowerDataset('flowers')\n",
    "dataset.load_data()\n",
    "dataset.preprocess_data()\n",
    "dataset.one_hot_encode()\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = split_data(dataset.images, dataset.labels, 0.75, 0.15, 0.10)\n",
    "\n",
    "# Print the dimensions of the preprocessed images\n",
    "dataset.print_dataset_dimensions()\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f\"Train set size: {len(x_train)}, Validation set size: {len(x_val)}, Test set size: {len(x_test)}\")\n",
    "\n",
    "# Print the unique classes in the training set\n",
    "unique_classes = sorted(set([label.index(1) for label in y_train]))\n",
    "print(f\"Unique classes in the training set: {unique_classes}\")\n",
    "\n",
    "num_classes = len(unique_classes)\n",
    "print(f\"Number of classes for prediction: {num_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f818a85a-2f0e-42d1-8201-60703ddfb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Layer class\n",
    "class Layer:\n",
    "    def forward(self, input_data):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        raise NotImplementedError\n",
    "\n",
    "# Convolutional Layer\n",
    "class ConvLayer(Layer):\n",
    "    def __init__(self, num_filters, filter_size, num_channels=3, padding=0, stride=1):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.filters = np.random.randn(num_filters, filter_size, filter_size, num_channels) / 9  # normalize values\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        # Assert that the input data has the expected shape\n",
    "        assert len(input_data.shape) == 4, f\"Expected input shape to be 4D, got {input_data.shape}\"\n",
    "        # Ensure the input data has four dimensions: batch size, height, width, and depth\n",
    "        if len(input_data.shape) < 4:\n",
    "            input_data = np.expand_dims(input_data, axis=0)  # Add a batch dimension\n",
    "        self.last_input = input_data\n",
    "        batch_size, h, w, d = input_data.shape\n",
    "\n",
    "        # Define input_padded here\n",
    "        input_padded = np.pad(input_data, (\n",
    "            (0, 0), \n",
    "            (self.padding, self.padding), \n",
    "            (self.padding, self.padding), \n",
    "            (0, 0)\n",
    "        ), 'constant')\n",
    "\n",
    "        new_h = int((h + 2 * self.padding - self.filter_size) / self.stride) + 1\n",
    "        new_w = int((w + 2 * self.padding - self.filter_size) / self.stride) + 1\n",
    "        output = np.zeros((batch_size, new_h, new_w, self.num_filters))\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for i in range(0, new_h):\n",
    "                for j in range(0, new_w):\n",
    "                    for f in range(self.num_filters):\n",
    "                        output[b, i, j, f] = np.sum(\n",
    "                            input_padded[b, i*self.stride:i*self.stride+self.filter_size, j*self.stride:j*self.stride+self.filter_size, :] * self.filters[f]\n",
    "                        )\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        d_filters = np.zeros(self.filters.shape)\n",
    "        d_input = np.zeros(self.last_input.shape)\n",
    "        batch_size, h_i, w_i, d_i = self.last_input.shape  # Add 'batch_size' here\n",
    "    \n",
    "        new_h = int((h_i + 2 * self.padding - self.filter_size) / self.stride) + 1\n",
    "        new_w = int((w_i + 2 * self.padding - self.filter_size) / self.stride) + 1\n",
    "    \n",
    "        for b in range(batch_size):  # Add a loop over the batch dimension\n",
    "            for i in range(0, new_h):\n",
    "                for j in range(0, new_w):\n",
    "                    for f in range(self.num_filters):\n",
    "                        # Ensure output_error and self.last_input do not contain any NaN or Inf values\n",
    "                        output_error[np.isnan(output_error)] = 0\n",
    "                        output_error[np.isinf(output_error)] = 0\n",
    "                        self.last_input[np.isnan(self.last_input)] = 0\n",
    "                        self.last_input[np.isinf(self.last_input)] = 0\n",
    "                        \n",
    "                        gradient_filters = np.clip(output_error[b, i, j, f] * self.last_input[b, i*self.stride:i*self.stride+self.filter_size, j*self.stride:j*self.stride+self.filter_size], -1e2, 1e2)\n",
    "                        gradient_filters = np.clip(gradient_filters, -1e2, 1e2)  # Clip values to a reasonable range\n",
    "                        d_filters[f] += gradient_filters\n",
    "                    \n",
    "                        gradient_input = self.filters[f] * output_error[b, i, j, f]\n",
    "                        gradient_input = np.clip(gradient_input, -1e2, 1e2)  # Clip values to a reasonable range\n",
    "                        d_input[b, i*self.stride:i*self.stride+self.filter_size, j*self.stride:j*self.stride+self.filter_size] += gradient_input\n",
    "        self.filters -= learning_rate * d_filters\n",
    "        return d_input\n",
    "\n",
    "    def reset(self):\n",
    "        self.last_input = None\n",
    "        \n",
    "# MaxPooling Layer\n",
    "class MaxPoolingLayer(Layer):\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.last_input = input_data\n",
    "        batch_size, h, w, num_filters = input_data.shape\n",
    "        output = np.zeros((batch_size, h // self.pool_size, w // self.pool_size, num_filters))\n",
    "        for b in range(batch_size):\n",
    "            for i in range(h // self.pool_size):\n",
    "                for j in range(w // self.pool_size):\n",
    "                    for f in range(num_filters):\n",
    "                        output[b, i, j, f] = np.max(input_data[b, i*self.pool_size:(i+1)*self.pool_size, j*self.pool_size:(j+1)*self.pool_size, f])\n",
    "        return output\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        d_input = np.zeros(self.last_input.shape)\n",
    "        batch_size, h, w, num_filters = self.last_input.shape\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for i in range(h // self.pool_size):\n",
    "                for j in range(w // self.pool_size):\n",
    "                    for f in range(num_filters):\n",
    "                        h_start = i * self.pool_size\n",
    "                        w_start = j * self.pool_size\n",
    "                        # Find the max index within the patch\n",
    "                        patch = self.last_input[b, h_start:h_start+self.pool_size, w_start:w_start+self.pool_size, f]\n",
    "                        max_index = np.argmax(patch)\n",
    "                        # Convert the index to 2D coordinates\n",
    "                        max_coord = np.unravel_index(max_index, patch.shape)\n",
    "                        # Propagate the gradient to the max location\n",
    "                        d_input[b, h_start + max_coord[0], w_start + max_coord[1], f] = output_error[b, i, j, f]\n",
    "\n",
    "        return d_input\n",
    "        \n",
    "class FlattenLayer(Layer):\n",
    "    def forward(self, input_data):\n",
    "        self.last_input_shape = input_data.shape\n",
    "        return input_data.reshape(input_data.shape[0], -1)\n",
    "        \n",
    "    def backward(self, output_error, learning_rate):\n",
    "        return output_error.reshape(self.last_input_shape)\n",
    "        \n",
    "# Dropout Layer\n",
    "class DropoutLayer(Layer):\n",
    "    def __init__(self, dropout_rate):\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.mask = (np.random.rand(*input_data.shape) > self.dropout_rate) / (1.0 - self.dropout_rate)\n",
    "        return input_data * self.mask\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        return output_error * self.mask\n",
    "\n",
    "# Dense Layer\n",
    "class DenseLayer(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2. / input_size)\n",
    "        self.biases = np.zeros(output_size)  # Ensure biases is a 1D array with length 'output_size'\n",
    "        \n",
    "    def forward(self, input_data):\n",
    "        # Assert that the input data is 2D after flattening\n",
    "        assert len(input_data.shape) == 2, f\"Expected input shape to be 2D, got {input_data.shape}\"\n",
    "        self.last_input = input_data\n",
    "        return np.dot(input_data, self.weights) + self.biases\n",
    "    \n",
    "    def backward(self, output_error, learning_rate):\n",
    "        d_weights = np.outer(self.last_input, output_error)\n",
    "        d_biases = output_error\n",
    "        self.weights -= learning_rate * d_weights\n",
    "        # Ensure 'd_biases' is a 1D array before subtraction\n",
    "        d_biases = d_biases.flatten() if d_biases.ndim > 1 else d_biases\n",
    "        self.biases -= learning_rate * d_biases\n",
    "        return np.dot(output_error, self.weights.T)\n",
    "        \n",
    "class SoftmaxLayer(Layer):\n",
    "    def forward(self, input_data):\n",
    "        # Reshape input_data to 2D if it's 1D\n",
    "        if input_data.ndim == 1:\n",
    "            input_data = input_data.reshape(1, -1)\n",
    "\n",
    "        input_data = np.clip(input_data, -1e2, 1e2)  # Clip values to a reasonable range\n",
    "        exp = np.exp(input_data - np.max(input_data, axis=1, keepdims=True))\n",
    "        return exp / np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        return output_error  # Error is passed straight through to the next layer\n",
    "        \n",
    "# ReLU Activation\n",
    "class ReLULayer(Layer):\n",
    "    def forward(self, input_data):\n",
    "        self.last_input = input_data\n",
    "        return np.maximum(0, input_data)\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        # The derivative of ReLU is 1 for positive inputs and 0 for negative inputs\n",
    "        return output_error * (self.last_input > 0)\n",
    "\n",
    "# Cross-Entropy Loss\n",
    "class CrossEntropyLoss:\n",
    "    def calculate_loss(self, predicted, actual):\n",
    "        # Convert 'actual' to a NumPy array if it's a list\n",
    "        actual = np.array(actual) if isinstance(actual, list) else actual\n",
    "        predicted = np.clip(predicted, 1e-9, 1 - 1e-9)\n",
    "        return -np.sum(actual * np.log(predicted)) # add small constant to avoid log(0)\n",
    "        \n",
    "    def calculate_gradient(self, predicted, actual):\n",
    "        # Convert 'actual' to a NumPy array if it's a list\n",
    "        actual = np.array(actual) if isinstance(actual, list) else actual\n",
    "        # Ensure 'actual' is a 2D array with the same shape as 'predicted'\n",
    "        if actual.ndim == 1:\n",
    "            actual = actual.reshape(1, -1)\n",
    "            # print(actual)\n",
    "        return predicted - actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b926a82-5ea1-4872-9689-f4c36ac62c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, num_classes, epochs=10, learning_rate=0.001, threshold=0.5, early_stopping_patience=5):\n",
    "        self.layers = [\n",
    "            ConvLayer(num_filters=32, filter_size=3, num_channels=3),  # num_channels is 3 for RGB images\n",
    "            ReLULayer(),\n",
    "            MaxPoolingLayer(pool_size=2),\n",
    "            ConvLayer(num_filters=64, filter_size=3, num_channels=32),  # num_channels is num_filters of previous ConvLayer\n",
    "            ReLULayer(),\n",
    "            MaxPoolingLayer(pool_size=2),\n",
    "            ConvLayer(num_filters=128, filter_size=3, num_channels=64),  # num_channels is num_filters of previous ConvLayer\n",
    "            ReLULayer(),\n",
    "            MaxPoolingLayer(pool_size=2),\n",
    "            ConvLayer(num_filters=256, filter_size=3, num_channels=128),  # num_channels is num_filters of previous ConvLayer\n",
    "            ReLULayer(),\n",
    "            MaxPoolingLayer(pool_size=2),\n",
    "            # ConvLayer(num_filters=512, filter_size=3, num_channels=256),  # num_channels is num_filters of previous ConvLayer\n",
    "            # ReLULayer(),\n",
    "            # MaxPoolingLayer(pool_size=2),\n",
    "            FlattenLayer(),\n",
    "            None, # -6   # Placeholder for first DenseLayer, will initialize properly later\n",
    "            ReLULayer(),\n",
    "            # DropoutLayer(dropout_rate=0.5),\n",
    "            # None, # -3   # Placeholder for second DenseLayer, will initialize properly later\n",
    "            # ReLULayer(),\n",
    "            DropoutLayer(dropout_rate=0.5),\n",
    "            None, # -1   # Placeholder for third DenseLayer, will initialize properly later\n",
    "            SoftmaxLayer()\n",
    "        ] \n",
    "        self.loss = CrossEntropyLoss()\n",
    "        self.num_classes = num_classes\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.best_loss = np.inf\n",
    "        self.patience_counter = 0\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            if layer is not None:\n",
    "                # Ensure X is a NumPy array\n",
    "                if isinstance(X, list):\n",
    "                    X = np.array(X)\n",
    "                # print(f\"+ Before forward - {type(layer).__name__}: {X.shape}\")\n",
    "                X = layer.forward(X)\n",
    "                # print(f\"- After forward - {type(layer).__name__}: {X.shape}\")\n",
    "        return X\n",
    "\n",
    "    def backward(self, output_error, learning_rate):\n",
    "        for layer in reversed(self.layers):\n",
    "            if layer is not None:\n",
    "                print(f\"+ Before backward - {type(layer).__name__}: {output_error.shape}\")\n",
    "                output_error = layer.backward(output_error, learning_rate)\n",
    "                print(f\"- After backward - {type(layer).__name__}: {output_error.shape}\")\n",
    "\n",
    "    def reset(self):\n",
    "        for layer in self.layers:\n",
    "            if hasattr(layer, 'last_input'):\n",
    "                layer.last_input = None\n",
    "\n",
    "    def validate(self, X_val, y_val):\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "    \n",
    "        # Iterate over each example in the validation set\n",
    "        for i in range(len(X_val)):\n",
    "            # Forward pass\n",
    "            input_data = np.expand_dims(X_val[i], axis=0)  # Add a batch dimension\n",
    "            output = self.forward(input_data)\n",
    "    \n",
    "            # Calculate loss and accuracy for the current validation example\n",
    "            val_loss = self.loss.calculate_loss(output, y_val[i])\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracy = (np.argmax(output, axis=1) == y_val[i]).mean()\n",
    "            val_accuracies.append(val_accuracy)\n",
    "    \n",
    "        # Calculate average loss and accuracy over the entire validation set\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        avg_val_accuracy = np.mean(val_accuracies)\n",
    "    \n",
    "        return avg_val_loss, avg_val_accuracy\n",
    "    \n",
    "    def calculate_loss(self, X, y):\n",
    "        return self.loss.calculate_loss(X, y)\n",
    "\n",
    "    def calculate_accuracy(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "    def min_max_scale(self, data):\n",
    "        min_val = min(data)\n",
    "        max_val = max(data)\n",
    "        range_val = max_val - min_val\n",
    "        if range_val == 0:\n",
    "            return [0 for _ in data]  # Return a list of zeros if all values are the same\n",
    "        scaled_data = [(value - min_val) / range_val for value in data]\n",
    "        return scaled_data\n",
    "        \n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        print(f\"Initial training data shape: {X_train[0].shape}\\n\")\n",
    "        \n",
    "        # Calculate the output size after the convolution and pooling layers\n",
    "        sample_output = self.forward(np.expand_dims(X_train[0], axis=0))\n",
    "        flattened_size = sample_output.size\n",
    "        \n",
    "        # Initialize the DenseLayers with the correct input size\n",
    "        self.layers[-6] = DenseLayer(input_size=flattened_size, output_size=128)  # First DenseLayer\n",
    "        self.layers[-3] = DenseLayer(input_size=128, output_size=64)  # Second DenseLayer\n",
    "        self.layers[-1] = DenseLayer(input_size=64, output_size=self.num_classes)  # Third DenseLayer\n",
    "\n",
    "        print(\"\\n  |====== Start training ======| \\n\")\n",
    "\n",
    "        train_losses = []\n",
    "        train_accuracies = []\n",
    "        val_losses = []\n",
    "        val_accuracies = []\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            batch_losses = []\n",
    "            batch_accuracies = []\n",
    "            \n",
    "            print(f\"Epoch {epoch} - Total number of rounds: {len(X_train)}\")\n",
    "            \n",
    "            \n",
    "            for j in range(len(X_train)):\n",
    "                print(f\"\\n=== start round {j}/{len(X_train)-1} - epoch {epoch} ===\\n\")\n",
    "                \n",
    "                # forward\n",
    "                input_data = np.expand_dims(X_train[j], axis=0)  # Add a batch dimension\n",
    "                output = self.forward(input_data)\n",
    "\n",
    "                print(\"---------------------------------------\")\n",
    "                \n",
    "                # backward\n",
    "                output_error = self.loss.calculate_gradient(output, y_train[j])\n",
    "                # Clip output error\n",
    "                threshold = 1e2  # Define an appropriate threshold\n",
    "                output_error = [[Limiting.clip(value, -threshold, threshold) for value in row] for row in output_error]\n",
    "                output_error = np.array([[self.clip(value, -threshold, threshold) for value in row] for row in output_error])\n",
    "                output_error = self.backward(output_error, self.learning_rate)\n",
    "                                \n",
    "                # Calculate loss and accuracy after the backward pass\n",
    "                batch_loss = self.loss.calculate_loss(output, y_train[j])\n",
    "                batch_losses.append(batch_loss)\n",
    "                batch_accuracy = (np.argmax(output, axis=1) == y_train[j]).mean()\n",
    "                batch_accuracies.append(batch_accuracy)\n",
    "            \n",
    "                self.reset()  # Reset the network's state after each forward pass\n",
    "                print(f\"\\n=== end round {j} - epoch {epoch} ===\\n\")\n",
    "\n",
    "            print(f\"\\n=== end epoch {epoch} ===\\n\")\n",
    "            \n",
    "            # Calculate the average training loss and accuracy for the epoch\n",
    "            avg_train_loss = np.mean(batch_losses)\n",
    "            # avg_train_loss = self.min_max_scale(avg_train_loss)\n",
    "            avg_train_accuracy = np.mean(batch_accuracies)\n",
    "            # avg_train_accuracy = self.min_max_scale(avg_train_accuracy)\n",
    "            \n",
    "            # Append the average metrics to the lists that track them across epochs\n",
    "            train_losses.append(avg_train_loss)\n",
    "            train_accuracies.append(avg_train_accuracy)\n",
    "\n",
    "            self.reset()\n",
    "\n",
    "            # Validation step\n",
    "            val_loss, val_accuracy = self.validate(X_val, y_val)\n",
    "            # val_loss = self.min_max_scale(val_loss)\n",
    "            # val_accuracy = self.min_max_scale(val_accuracy)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            \n",
    "            print(f\"Epoch: {epoch}, Train Loss: {avg_train_loss}, Train Accuracy: {avg_train_accuracy}, Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "    \n",
    "            if val_loss < self.best_loss:\n",
    "                self.best_loss = val_loss\n",
    "                self.patience_counter = 0\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "            if self.patience_counter >= self.early_stopping_patience:\n",
    "                print(\"Early stopping due to no improvement in validation loss.\")\n",
    "                break\n",
    "\n",
    "        print(\"Training finished.\")\n",
    "        print(f\"Best validation accuracy achieved: {self.best_loss}\")\n",
    "\n",
    "        self.plot_results(train_losses, train_accuracies, val_losses, val_accuracies)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for i in range(len(X)):\n",
    "            # Ensure the input data has four dimensions: batch size, height, width, and depth\n",
    "            input_data = np.expand_dims(X[i], axis=0)  # Add a batch dimension\n",
    "            output = self.forward(input_data)\n",
    "            predictions.append(np.argmax(output, axis=1))  # Use axis=1 to get the class index\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    def plot_results(self, train_losses, train_accuracies, val_losses, val_accuracies):\n",
    "        actual_epochs = min(len(train_losses), len(train_accuracies), len(val_losses), len(val_accuracies))\n",
    "        assert actual_epochs > 0, \"No data to plot.\"\n",
    "    \n",
    "        # If 'val_losses' is a nested list, flatten it\n",
    "        if isinstance(val_losses[0], list):\n",
    "            val_losses = [loss for sublist in val_losses for loss in sublist]\n",
    "        \n",
    "        epochs = range(1, actual_epochs + 1)\n",
    "    \n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, train_losses[:actual_epochs], 'g', label='Training loss')\n",
    "        plt.plot(epochs, val_losses[:actual_epochs], 'b', label='Validation loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, train_accuracies[:actual_epochs], 'g', label='Training accuracy')\n",
    "        plt.plot(epochs, val_accuracies[:actual_epochs], 'b', label='Validation accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120993d8-0d53-4c5f-9d8c-2dc201c6e02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial training data shape: (150, 150, 3)\n",
      "\n",
      "\n",
      "  |====== Start training ======| \n",
      "\n",
      "Epoch 0 - Total number of rounds: 15\n",
      "\n",
      "=== start round 0/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 0 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 1/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 1 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 2/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 2 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 3/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/student14/phucpg/venv/lib/python3.11/site-packages/numpy/core/numeric.py:925: RuntimeWarning: overflow encountered in multiply\n",
      "  return multiply(a.ravel()[:, newaxis], b.ravel()[newaxis, :], out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 3 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 4/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 4 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 5/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 5 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 6/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 6 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 7/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 7 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 8/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 8 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 9/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 9 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 10/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 10 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 11/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 11 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 12/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 12 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 13/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 13 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== start round 14/14 - epoch 0 ===\n",
      "\n",
      "---------------------------------------\n",
      "+ Before backward - DenseLayer: (1, 10)\n",
      "- After backward - DenseLayer: (1, 64)\n",
      "+ Before backward - DenseLayer: (1, 64)\n",
      "- After backward - DenseLayer: (1, 128)\n",
      "+ Before backward - ReLULayer: (1, 128)\n",
      "- After backward - ReLULayer: (1, 128)\n",
      "+ Before backward - DenseLayer: (1, 128)\n",
      "- After backward - DenseLayer: (1, 2048)\n",
      "+ Before backward - ReLULayer: (1, 2048)\n",
      "- After backward - ReLULayer: (1, 2048)\n",
      "+ Before backward - FlattenLayer: (1, 2048)\n",
      "- After backward - FlattenLayer: (1, 2, 2, 512)\n",
      "+ Before backward - MaxPoolingLayer: (1, 2, 2, 512)\n",
      "- After backward - MaxPoolingLayer: (1, 5, 5, 512)\n",
      "+ Before backward - ReLULayer: (1, 5, 5, 512)\n",
      "- After backward - ReLULayer: (1, 5, 5, 512)\n",
      "+ Before backward - ConvLayer: (1, 5, 5, 512)\n",
      "- After backward - ConvLayer: (1, 7, 7, 256)\n",
      "+ Before backward - MaxPoolingLayer: (1, 7, 7, 256)\n",
      "- After backward - MaxPoolingLayer: (1, 15, 15, 256)\n",
      "+ Before backward - ReLULayer: (1, 15, 15, 256)\n",
      "- After backward - ReLULayer: (1, 15, 15, 256)\n",
      "+ Before backward - ConvLayer: (1, 15, 15, 256)\n",
      "- After backward - ConvLayer: (1, 17, 17, 128)\n",
      "+ Before backward - MaxPoolingLayer: (1, 17, 17, 128)\n",
      "- After backward - MaxPoolingLayer: (1, 34, 34, 128)\n",
      "+ Before backward - ReLULayer: (1, 34, 34, 128)\n",
      "- After backward - ReLULayer: (1, 34, 34, 128)\n",
      "+ Before backward - ConvLayer: (1, 34, 34, 128)\n",
      "- After backward - ConvLayer: (1, 36, 36, 64)\n",
      "+ Before backward - MaxPoolingLayer: (1, 36, 36, 64)\n",
      "- After backward - MaxPoolingLayer: (1, 72, 72, 64)\n",
      "+ Before backward - ReLULayer: (1, 72, 72, 64)\n",
      "- After backward - ReLULayer: (1, 72, 72, 64)\n",
      "+ Before backward - ConvLayer: (1, 72, 72, 64)\n",
      "- After backward - ConvLayer: (1, 74, 74, 32)\n",
      "+ Before backward - MaxPoolingLayer: (1, 74, 74, 32)\n",
      "- After backward - MaxPoolingLayer: (1, 148, 148, 32)\n",
      "+ Before backward - ReLULayer: (1, 148, 148, 32)\n",
      "- After backward - ReLULayer: (1, 148, 148, 32)\n",
      "+ Before backward - ConvLayer: (1, 148, 148, 32)\n",
      "- After backward - ConvLayer: (1, 150, 150, 3)\n",
      "\n",
      "=== end round 14 - epoch 0 ===\n",
      "\n",
      "\n",
      "=== end epoch 0 ===\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CNN.min_max_scale() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m early_stopping_patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      8\u001b[0m cnn \u001b[38;5;241m=\u001b[39m CNN(num_classes, epochs, learning_rate, threshold, early_stopping_patience)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 157\u001b[0m, in \u001b[0;36mCNN.train\u001b[0;34m(self, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Calculate the average training loss and accuracy for the epoch\u001b[39;00m\n\u001b[1;32m    156\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(batch_losses)\n\u001b[0;32m--> 157\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_max_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mavg_train_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m avg_train_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(batch_accuracies)\n\u001b[1;32m    159\u001b[0m avg_train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_max_scale(avg_train_accuracy)\n",
      "\u001b[0;31mTypeError\u001b[0m: CNN.min_max_scale() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Adjust the values to train\n",
    "num_classes = num_classes\n",
    "epochs = 2\n",
    "learning_rate = 0.0001\n",
    "threshold = 0.5\n",
    "early_stopping_patience = 5\n",
    "\n",
    "cnn = CNN(num_classes, epochs, learning_rate, threshold, early_stopping_patience)\n",
    "cnn.train(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21337c04-c9f5-413a-87b8-72d93bdfe88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
