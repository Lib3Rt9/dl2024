{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a2be59-1599-488c-a07e-be32e73da290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # to process the data\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3e9f9f-ff9b-40a2-bf06-8894b36a5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 images\n",
      "Shape of the preprocessed images: 10 images, each with 22500 pixels\n",
      "Dimensions of the first preprocessed image: 22500 pixels\n",
      "Train set size: 7, Validation set size: 1, Test set size: 2\n",
      "Unique classes in the training set: {'orchids', 'daisies', 'peonies', 'hibiscus', 'lilies', 'hydrangeas', 'tulip'}\n"
     ]
    }
   ],
   "source": [
    "class FlowerDataset:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "    def load_data(self):\n",
    "        for i, img in enumerate(os.listdir(self.directory)):\n",
    "            if i >= 10:  # only load the first 10 images\n",
    "                break\n",
    "            try:\n",
    "                img_path = os.path.join(self.directory, img)\n",
    "                with Image.open(img_path) as img_array:  # read the image\n",
    "                    gray_array = img_array.convert('L')  # ensure image is grayscale\n",
    "                    resized_array = gray_array.resize((150, 150))  # resize the image\n",
    "                    self.images.append(list(resized_array.getdata()))  # keep image in 1D\n",
    "                    label = img.split('_')[0]  # extract label from filename\n",
    "                    self.labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {img}: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        # Normalize pixel values\n",
    "        self.images = [[pixel / 255.0 for pixel in image] for image in self.images]\n",
    "        print(f\"Loaded {len(self.images)} images\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "dataset = FlowerDataset('flowers')\n",
    "dataset.load_data()\n",
    "dataset.preprocess_data()\n",
    "\n",
    "# Print the shape of the preprocessed images\n",
    "print(f\"Shape of the preprocessed images: {len(dataset.images)} images, each with {len(dataset.images[0])} pixels\")\n",
    "\n",
    "# Dimensions of the first preprocessed image\n",
    "print(f\"Dimensions of the first preprocessed image: {len(dataset.images[0])} pixels\")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# Custom function to split the dataset\n",
    "def custom_train_test_split(data, labels, train_size):\n",
    "    train_count = int(len(data) * train_size)\n",
    "    return data[:train_count], data[train_count:], labels[:train_count], labels[train_count:]\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "x_train, x_temp, y_train, y_temp = custom_train_test_split(dataset.images, dataset.labels, train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set, validation is now 15%\n",
    "val_count = int(len(x_temp) * (validation_ratio / (test_ratio + validation_ratio)))\n",
    "x_val, x_test = x_temp[:val_count], x_temp[val_count:]\n",
    "y_val, y_test = y_temp[:val_count], y_temp[val_count:]\n",
    "\n",
    "# Print the sizes of the datasets\n",
    "print(f\"Train set size: {len(x_train)}, Validation set size: {len(x_val)}, Test set size: {len(x_test)}\")\n",
    "\n",
    "# Print the unique classes in the training set\n",
    "unique_classes = set(y_train)\n",
    "print(f\"Unique classes in the training set: {unique_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f818a85a-2f0e-42d1-8201-60703ddfb2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    if isinstance(x, list):\n",
    "        return [max(0, xi) for xi in x]\n",
    "    else:\n",
    "        return max(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    if isinstance(x, list):\n",
    "        return [1 if xi > 0 else 0 for xi in x]\n",
    "    else:\n",
    "        return 1 if x > 0 else 0\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return sum((yt - yp) ** 2 for yt, yp in zip(y_true, y_pred)) / len(y_true)\n",
    "\n",
    "def gradient_mse(y_true, y_pred):\n",
    "    return [2 * (yp - yt) for yt, yp in zip(y_true, y_pred)]\n",
    "\n",
    "def softmax(x):\n",
    "    exps = [math.exp(i) for i in x]\n",
    "    sum_of_exps = sum(exps)\n",
    "    return [j / sum_of_exps for j in exps]\n",
    "\n",
    "def cross_entropy(predictions, targets):\n",
    "    # Assuming predictions is a list of probabilities and targets is a list of one-hot encoded classes\n",
    "    N = len(predictions)\n",
    "    ce = 0\n",
    "    for p, t in zip(predictions, targets):\n",
    "        ce -= t * math.log(p) if p > 0 else 0  # Adding check to prevent math domain error\n",
    "    ce /= N\n",
    "    return ce\n",
    "\n",
    "def dot_product(x, y):\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "def matrix_multiply(X, Y):\n",
    "    return [[dot_product(X_row, Y_col) for Y_col in zip(*Y)] for X_row in X]\n",
    "\n",
    "def transpose(matrix):\n",
    "    return list(map(list, zip(*matrix)))\n",
    "\n",
    "def matrix_addition(X, Y):\n",
    "    return [[xi + yi for xi, yi in zip(x, y)] for x, y in zip(X, Y)]\n",
    "\n",
    "def scalar_multiply(matrix, scalar):\n",
    "    return [[scalar * element for element in row] for row in matrix]\n",
    "\n",
    "def reshape_input(flat_input, image_height, image_width):\n",
    "    return [flat_input[i * image_width:(i + 1) * image_width] for i in range(image_height)]\n",
    "    \n",
    "# Layer classes\n",
    "class Layer:\n",
    "    def forward(self, input):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def backward(self, input, gradient):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Conv2D(Layer):\n",
    "    def __init__(self, num_filters, filter_size, image_height, image_width):\n",
    "        self.num_filters = num_filters\n",
    "        self.filter_size = filter_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        # Initialize filters with small random values\n",
    "        self.filters = [[random.uniform(-0.1, 0.1) for _ in range(filter_size * filter_size)] for _ in range(num_filters)]\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Calculate the padding size\n",
    "        padding = self.filter_size // 2\n",
    "\n",
    "        # Reshape 1D input into 2D and pad with zeros\n",
    "        input_2d = [input[i * self.image_width:(i + 1) * self.image_width] for i in range(self.image_height)]\n",
    "        padded_input = [[0] * (self.image_width + 2 * padding) for _ in range(padding)] + \\\n",
    "                       [[0] * padding + row + [0] * padding for row in input_2d] + \\\n",
    "                       [[0] * (self.image_width + 2 * padding) for _ in range(padding)]\n",
    "        \n",
    "        # Adjusted output dimensions after padding\n",
    "        output_height = len(padded_input) - self.filter_size + 1\n",
    "        output_width = len(padded_input[0]) - self.filter_size + 1\n",
    "        output = [[0 for _ in range(output_width)] for _ in range(output_height)]\n",
    "\n",
    "        print(padded_input[9])\n",
    "        \n",
    "        # Perform the convolution operation\n",
    "        for f in range(self.num_filters):\n",
    "            for i in range(output_height):\n",
    "                for j in range(output_width):\n",
    "                    print(i+j)\n",
    "                    \n",
    "                    region = [padded_input[i+x][j+y] for x in range(self.filter_size) for y in range(self.filter_size)]\n",
    "                    output[i][j] = sum(r * k for r, k in zip(region, self.filters[f]))\n",
    "\n",
    "                    print(f\"Filter {f}, Position ({i}, {j}):\")\n",
    "                    print(\"Region:\", region)\n",
    "                    print(\"Filter:\", self.filters[f])\n",
    "                    print(\"Output Value:\", output[i][j])\n",
    "        return output\n",
    "\n",
    "    def backward(self, input, output_gradient, learning_rate):\n",
    "        # Initialize gradients for filters with zeros\n",
    "        d_filters = [[[0 for _ in range(self.filter_size * self.filter_size)] for _ in range(self.filter_size)] for _ in range(self.num_filters)]\n",
    "        \n",
    "        # Initialize input_gradient with zeros\n",
    "        input_gradient = [[0 for _ in range(self.image_width)] for _ in range(self.image_height)]\n",
    "\n",
    "        # Loop over the output gradient and filters to accumulate the input_gradient\n",
    "        for f in range(self.num_filters):\n",
    "            for i in range(len(output_gradient)):\n",
    "                for j in range(len(output_gradient[0])):\n",
    "                    # Determine the region of the input that contributed to the output_gradient[i][j]\n",
    "                    for x in range(self.filter_size):\n",
    "                        for y in range(self.filter_size):\n",
    "                            # Calculate the coordinates in the input\n",
    "                            in_x = i + x\n",
    "                            in_y = j + y\n",
    "                            # Accumulate the gradient for the input\n",
    "                            if 0 <= in_x < self.image_height and 0 <= in_y < self.image_width:\n",
    "                                input_gradient[in_x][in_y] += output_gradient[i][j] * self.filters[f][x * self.filter_size + y]\n",
    "                            # Accumulate the gradient for the filter\n",
    "                            d_filters[f][x * self.filter_size + y] += input_2d[in_x][in_y] * output_gradient[i][j]\n",
    "\n",
    "        # Update filters with the calculated gradients\n",
    "        for f in range(self.num_filters):\n",
    "            for k in range(self.filter_size * self.filter_size):\n",
    "                self.filters[f][k] -= learning_rate * d_filters[f][k]\n",
    "\n",
    "        return input_gradient\n",
    "\n",
    "class MaxPooling2D(Layer):\n",
    "    def __init__(self, pool_size, image_height, image_width):\n",
    "        self.pool_size = pool_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Reshape 1D input into 2D\n",
    "        input = reshape_input(input, self.image_height, self.image_width)\n",
    "        # Rest of the code remains the same...\n",
    "\n",
    "class Flatten(Layer):\n",
    "    def forward(self, input):\n",
    "        self.input_shape = (len(input), len(input[0]))  # save this for backward pass\n",
    "        return [item for sublist in input for item in sublist]  # flatten the list\n",
    "\n",
    "    def backward(self, input, gradient):\n",
    "        return [gradient[i:i+self.input_shape[1]] for i in range(0, len(gradient), self.input_shape[1])]\n",
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = [[random.random() for _ in range(num_inputs)] for _ in range(num_outputs)]\n",
    "        self.biases = [random.random() for _ in range(num_outputs)]\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Compute the weighted sum of inputs plus biases\n",
    "        return [dot_product(weights_row, input) + b for weights_row, b in zip(self.weights, self.biases)]\n",
    "\n",
    "    def backward(self, input, gradient):\n",
    "        # Compute gradients with respect to weights and biases\n",
    "        d_weights = scalar_multiply(transpose([gradient]), [input])\n",
    "        d_biases = gradient\n",
    "        d_input = dot_product(self.weights, gradient)\n",
    "        return d_input, d_weights, d_biases\n",
    "\n",
    "class Dropout(Layer):\n",
    "    def __init__(self, rate):\n",
    "        self.rate = rate\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input_shape = (len(input), len(input[0]))  # save this for backward pass\n",
    "        self.mask = [[random.random() > self.rate for _ in range(self.input_shape[1])] for _ in range(self.input_shape[0])]\n",
    "        return [[input[i][j] * self.mask[i][j] for j in range(self.input_shape[1])] for i in range(self.input_shape[0])]\n",
    "\n",
    "    def backward(self, input, gradient):\n",
    "        return [[gradient[i][j] * self.mask[i][j] for j in range(self.input_shape[1])] for i in range(self.input_shape[0])]\n",
    "\n",
    "# Activation functions as layers\n",
    "class ReLU(Layer):\n",
    "    def forward(self, input):\n",
    "        output = [relu(x) for x in input]\n",
    "        return output\n",
    "\n",
    "    def backward(self, input, gradient):\n",
    "        # Apply the derivative of ReLU to the gradient\n",
    "        return [g * relu_derivative(x) for x, g in zip(input, gradient)]\n",
    "\n",
    "# Loss function as a class\n",
    "class SoftmaxCrossEntropyLoss:\n",
    "    def forward(self, logits, labels):\n",
    "        self.predictions = softmax(logits)\n",
    "        return cross_entropy(self.predictions, labels)\n",
    "\n",
    "    def backward(self, logits, labels):\n",
    "        return [p - l for p, l in zip(self.predictions, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b926a82-5ea1-4872-9689-f4c36ac62c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNNModel:\n",
    "    def __init__(self, num_epochs, learning_rate, threshold, early_stopping_rounds):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.layers = [\n",
    "            Conv2D(num_filters=32, filter_size=3, image_height=150, image_width=150),\n",
    "            ReLU(),\n",
    "            MaxPooling2D(pool_size=2, image_height=148, image_width=148),  # image size is reduced by filter_size - 1\n",
    "            Flatten(),\n",
    "            Dense(num_inputs=74*74*32, num_outputs=10),  # 74 is the new image size after pooling, 32 is the number of filters, 10 is the number of classes\n",
    "            Dropout(rate=0.5)\n",
    "        ]\n",
    "        self.loss = SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def compute_loss_and_gradients(self, x, y):\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss.forward(logits, y)\n",
    "        gradient = self.loss.backward(logits, y)\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient = layer.backward(x, gradient)\n",
    "        return loss\n",
    "\n",
    "    def update_weights(self):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dense) or isinstance(layer, Conv2D):\n",
    "                for i, (w, g) in enumerate(zip(layer.weights, layer.d_weights)):\n",
    "                    for j, _ in enumerate(w):\n",
    "                        layer.weights[i][j] -= self.learning_rate * g[j]\n",
    "                for i, b in enumerate(layer.biases):\n",
    "                    layer.biases[i] -= self.learning_rate * layer.d_biases[i]\n",
    "\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        history = []\n",
    "        best_val_loss = float('inf')\n",
    "        no_improvement_rounds = 0\n",
    "\n",
    "        for epoch in range(self.num_epochs):\n",
    "            loss = self.compute_loss_and_gradients(x_train, y_train)\n",
    "            self.update_weights()\n",
    "            val_loss = self.compute_loss_and_gradients(x_val, y_val)\n",
    "\n",
    "            if val_loss < best_val_loss - self.threshold:\n",
    "                best_val_loss = val_loss\n",
    "                no_improvement_rounds = 0\n",
    "            else:\n",
    "                no_improvement_rounds += 1\n",
    "\n",
    "            if no_improvement_rounds >= self.early_stopping_rounds:\n",
    "                print(f\"Early stopping on epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "            history.append((loss, val_loss))\n",
    "            print(f\"Epoch {epoch}: loss = {loss}, val_loss = {val_loss}\")\n",
    "\n",
    "        return history\n",
    "\n",
    "\n",
    "\n",
    "model = CustomCNNModel(num_epochs=10, learning_rate=0.01, threshold=0.01, early_stopping_rounds=5)\n",
    "history = model.train(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e022751d-edd5-4843-9136-cfc943b2a5b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cfe682-9d17-4aea-afdb-14218be9633c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
