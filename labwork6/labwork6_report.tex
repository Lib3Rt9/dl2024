\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\setcounter{secnumdepth}{4}

\title{Labwork 5: Convolutional Neural Network}
\author{Pham Gia Phuc}
\date{May 2024}

\begin{document}

\maketitle

\setlength\parindent{0pt}

\section{Introduction}

    \subsection{Definition}

    A Convolutional Neural Network (CNN) is a type of deep learning algorithm used for image recognition and processing tasks. It is specifically designed to automatically and adaptively learn spatial hierarchies of features from input data.
    
    \subsection{Usage}

    CNNs are widely used in various fields such as image and video recognition, medical image analysis, natural language processing, and many other tasks where the input data has a grid-like topology.

    CNNs have demonstrated great success in image classification, object detection, and semantic segmentation tasks. They are robust to variations in input and are capable of learning hierarchical representations of features, making them extremely effective for a wide range of visual processing tasks.
    
\section{Implementation}

    \subsection{Data preparation}

        \subsubsection{Data introduction}
            The dataset at hand is a substantial collection of 15,000 images, carefully organized into three distinct classes: shoe, sandal, and boot, with 5000 images allocated to each class. This well-balanced distribution sets a solid foundation for training and evaluating machine learning models designed for image classification tasks. These images are expected to encapsulate a wide range of footwear types, representing various styles, colors, textures, and patterns. The diversity within each class and the overall dataset is paramount in ensuring the robustness and effectiveness of the models trained using this data.

            In terms of labeling, each image in the dataset is accurately tagged with one of the three classes, maintaining the integrity and clarity of the dataset. The correctness and consistency of the labeling process are crucial as they directly impact the model's ability to learn and generalize effectively. Furthermore, the uniformity in labeling enables a seamless and structured approach to model training, testing, and evaluation, thereby fostering a reliable foundation for the development of sophisticated image classification algorithms.

        \subsubsection{Data preprocessing}
            In the preprocessing stage, all images from the dataset were converted into numpy arrays, each with a uniform resolution of 204x153 pixels. This transformation process was essential to standardize the image data and prepare it for subsequent model training and analysis. The conversion to numpy arrays enabled efficient manipulation and processing of the image data using numerical operations, while ensuring consistency in the input dimensions for the machine learning models. The normalization of pixel values and resizing of the images to a consistent resolution minimized distortions and variations in aspect ratios, facilitating model convergence during training and ensuring numerical stability. This approach not only optimized data uniformity but also streamlined the workflow of developing and fine-tuning machine learning models, aligning with best practices in image data preprocessing. Furthermore, the standardized numpy arrays are compatible with popular machine learning libraries, such as TensorFlow and PyTorch, allowing for seamless integration into model training pipelines.
            
            The impact of this preprocessing step extends to the quality and effectiveness of model training. By converting the images to numpy arrays with standardized resolutions, the dataset's uniformity was enhanced, promoting better model performance and generalization. Additionally, the efficient handling of large-scale image datasets using numpy arrays established a solid foundation for subsequent preprocessing steps, such as data augmentation and dataset splitting. Following the conversion to numpy arrays, data augmentation techniques were applied to further enrich the dataset, while the preprocessed numpy arrays were divided into training, validation, and test sets to facilitate model training, evaluation, and performance assessment. Overall, this preprocessing stage played a pivotal role in laying the groundwork for effective model training and analysis, setting a strong foundation for developing sophisticated image classification models and ensuring the dataset's suitability for driving innovations in the field of computer vision.
    
    \subsection{Model implementation}

        The custom Convolutional Neural Network (CNN) model outlined here is structured for the task of image classification. It processes input images of size 153x204 pixels with three color channels (RGB). The model is composed of multiple layers, each contributing to the gradual transformation of input images into features that can be used to classify the images into one of three categories.
            
            \subsubsection{Convolutional Layers}
                The model begins with a convolutional layer that applies 32 filters of size 3x3 to the input images. This operation scans the images to detect basic features like edges and textures. The activation function used is ReLU (Rectified Linear Unit), which helps the model learn non-linear patterns.
                
                Following this, additional convolutional layers with increasing numbers of filters (64 and 128) continue to process the images. These layers progressively detect more complex features as the data passes through the network.

            \subsubsection{Max Pooling Layers}

                After each convolutional layer, a max pooling layer is used to reduce the size of the feature maps. Pooling layers down-sample the input by taking the maximum value from a set of pixels, thus reducing the dimensionality of the data and highlighting the most important features. This also helps in making the model more computationally efficient and less sensitive to small variations in the input.
                
            \subsubsection{Flattening Layer}

                Once the convolutional and pooling operations are complete, the feature maps are flattened into a single long vector. This flattening step is necessary to prepare the data for the fully connected layers that follow.
                
            \subsubsection{Fully Connected Layers (Dense Layers)}

                The flattened data is then passed through a fully connected layer with 128 units. Each unit in this layer is connected to every input, enabling the model to learn complex combinations of the features extracted by the convolutional layers. The ReLU activation function is again used here.
                
                A dropout layer is included after this fully connected layer. Dropout is a regularization technique where a fraction of the neurons (10% in this case) are randomly set to zero during training. This prevents the model from overfitting by ensuring it does not rely too heavily on any single neuron.

            \subsubsection{Output Layer}

                The final layer of the model is another fully connected layer with 3 units, corresponding to the three output classes. A softmax activation function is used, which converts the outputs into probabilities that sum to one. This allows the model to make a prediction by selecting the class with the highest probability.

        
\section{Evaluation}

    The custom CNN model was trained over 10 epochs to classify images into three categories: shoes, sandals, and boots. The dataset was split into training and testing sets with an 80-20 ratio, ensuring that the model had a diverse and adequate amount of data for training and validation. The Adam optimizer with a learning rate of 0.001 was used, and categorical crossentropy was the loss function, with accuracy as the performance metric.

    During the first epoch, the model showed a promising start, achieving a training accuracy of 86.54% and a validation accuracy of 93.77%. The validation loss improved significantly from infinity to 0.1843, indicating that the model was effectively learning to generalize from the training data. This improvement led to the first model checkpoint being saved as best_model.h5.

    In the second epoch, the model continued to perform well, with a training accuracy of 94.64%. However, the validation loss slightly increased to 0.2006, and the validation accuracy slightly decreased to 93.00%. Despite this, the model maintained high performance, suggesting that it was still learning effectively.

    By the third epoch, the training accuracy increased to 96.93%, and the validation accuracy improved to 96.33%. The validation loss decreased to 0.1278, the lowest recorded during training, leading to another model checkpoint. This indicated that the model was improving its ability to generalize to unseen data.

    In subsequent epochs, the training accuracy continued to rise, reaching 98.41% by the sixth epoch. However, the validation loss began to show signs of overfitting, fluctuating and not consistently improving. The validation accuracy remained high, with slight variations, indicating that the model was still performing well but starting to overfit the training data.

    The seventh to tenth epochs highlighted the overfitting trend more clearly. The training accuracy remained high, but the validation loss did not improve from the best recorded in the third epoch (0.12775). Notably, the validation loss spiked to 0.5370 in the ninth epoch, with a corresponding drop in validation accuracy to 88.70%. This further indicated overfitting, where the model memorized the training data rather than generalizing.

    Despite these fluctuations, the final epoch concluded with a validation accuracy of 96.77%, suggesting that the model retained strong generalization capabilities. However, the best validation loss achieved remained at 0.12775 from the third epoch.

\section{Conclusion}
    
    This project successfully designed and trained a custom Convolutional Neural Network (CNN) to classify images into shoes, sandals, and boots. The model achieved a peak training accuracy of 98.87% and a validation accuracy of 96.77%, demonstrating strong learning capabilities.

    Initial training epochs showed significant improvements in accuracy and loss. However, signs of overfitting emerged in later epochs, where the validation loss fluctuated despite high training accuracy. To address this, strategies such as increased dropout, data augmentation, and early stopping are recommended.

    The final model, saved as final\_model.h5, and the best performing model,   saved as best\_model.h5, indicate robust performance and potential for practical image classification applications. This project provides a solid foundation for future work in deep learning-based image classification, with room for enhancements to improve generalization.

\end{document}
